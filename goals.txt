Paper title: It’s Raw! Audio Generation with State-Space Models
Paper link: https://proceedings.mlr.press/v162/goel22a/goel22a.pdf

Qualitative results: Examples on section 1, https://hazyresearch.stanford.edu/sashimi-examples/

Quantitative results: Table 4, column 1. Reproducing columns 2 and 3 is not feasible because it relies on human feedback.

—— version 1 submission ——

First, we have tested the model on MNIST and obtained good results.
However, we have failed to reproduce the targeted results.
The samples from the model resemble piano sounds but they lack musicality. It sounds as if someone was pressing the piano keys randomly.
Our average NLL on test dataset is 5.192 (in base 2) which is nowhere near our target 1.294.

We have already outlined the challenges we faced at the end of main.ipynb.
Based on these, our future work plan is:
- Check whether there are any remaining bugs in our implementation.
- Train with different hyperparameters and optimizers.
- Train for longer durations if our resources allow.
- If all else fails, train on a different dataset. In particular, SC09 may be simpler.
